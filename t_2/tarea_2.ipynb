{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e80165bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† PyTorch - GPU disponible: True\n",
      "‚öôÔ∏è TensorFlow - GPU detectada: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"üß† PyTorch - GPU disponible:\", torch.cuda.is_available())\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"‚öôÔ∏è TensorFlow - GPU detectada:\", tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3a1e162",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750382250.186038  112172 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750382250.217477  112172 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1750382250.453314  112172 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750382250.453392  112172 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750382250.453394  112172 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750382250.453395  112172 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Solo errores, no warnings ni info\n",
    "\n",
    "# === M√≥dulos est√°ndar ===\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "\n",
    "# === Keras ===\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential # type: ignore\n",
    "from tensorflow.keras.layers import Dense, Input # type: ignore\n",
    "from tensorflow.keras.initializers import GlorotUniform # type: ignore\n",
    "from tensorflow.keras.optimizers import SGD as KSGD, Adam as KAdam # type: ignore\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy # type: ignore\n",
    "\n",
    "# === PyTorch ===\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# === Sklearn ===\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# === other imports ===\n",
    "import numpy as np, csv, os, time, itertools\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import matplotlib.pyplot as plt\n",
    "import glob, os, math, io, imageio, pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12b66e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(framework, seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    if framework == \"keras\":\n",
    "        tf.random.set_seed(seed)\n",
    "        model = Sequential([\n",
    "            Dense(1024, activation='relu', kernel_initializer=GlorotUniform(seed), input_shape=(32*32*3,)),\n",
    "            Dense(512,  activation='relu', kernel_initializer=GlorotUniform(seed)),\n",
    "            Dense(256,  activation='relu', kernel_initializer=GlorotUniform(seed)),\n",
    "            Dense(128,  activation='relu', kernel_initializer=GlorotUniform(seed)),\n",
    "            Dense(10,   activation='softmax',  # ‚Üê salida softmax, 5.¬™ capa\n",
    "                kernel_initializer=GlorotUniform(seed))\n",
    "        ])\n",
    "        return model\n",
    "\n",
    "\n",
    "    elif framework == \"torch\":\n",
    "        torch.manual_seed(seed)\n",
    "        model = nn.Sequential(\n",
    "            nn.Linear(3072, 1024), nn.ReLU(),   \n",
    "            nn.Linear(1024, 512),  nn.ReLU(),   \n",
    "            nn.Linear(512, 256),   nn.ReLU(),   \n",
    "            nn.Linear(256, 128),   nn.ReLU(),   \n",
    "            nn.Linear(128, 10)                 \n",
    "        )\n",
    "        return model\n",
    "\n",
    "\n",
    "    elif framework == \"sklearn\":\n",
    "        model = MLPClassifier(\n",
    "            hidden_layer_sizes=(1024, 512, 256, 128),\n",
    "            activation='relu',\n",
    "            solver='adam',\n",
    "            max_iter=1,\n",
    "            random_state=seed\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Framework '{framework}' no soportado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6cfed77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, numpy as np\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import SGD as KSGD, Adam as KAdam\n",
    "import torch.nn as nn, torch.optim as optim, torch\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import joblib\n",
    "\n",
    "def train_network(network, X, y, optimizer, learning_rate, batch_size, timeout):\n",
    "    results = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Crea carpeta si no existe\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "    # Etiqueta com√∫n para el archivo\n",
    "    tag = f\"{optimizer}_bs{batch_size}_lr{learning_rate}\"\n",
    "\n",
    "    print(f\"üîç Detectando tipo de red: {type(network)}\")\n",
    "\n",
    "    # ================ KERAS ================\n",
    "    try:\n",
    "        if hasattr(network, \"train_on_batch\") and hasattr(network, \"compile\"):\n",
    "            print(\"‚úÖ Red Keras detectada. Iniciando entrenamiento‚Ä¶\")\n",
    "            network.compile(\n",
    "                optimizer=KAdam(learning_rate) if optimizer == \"adam\" else KSGD(learning_rate),\n",
    "                loss=SparseCategoricalCrossentropy(),\n",
    "            )\n",
    "\n",
    "            num_samples = X.shape[0]\n",
    "            while True:\n",
    "                if time.time() - start_time >= timeout - 0.1:\n",
    "                    break\n",
    "                idx = np.random.choice(num_samples, batch_size, replace=False)\n",
    "                loss = network.train_on_batch(X[idx], y[idx])\n",
    "                elapsed = round(time.time() - start_time, 4)\n",
    "                results.append((elapsed, float(loss)))\n",
    "\n",
    "            # ‚îÄ‚îÄ‚îÄ Guardar modelo ‚îÄ‚îÄ‚îÄ\n",
    "            path = f\"models/keras_{tag}.keras\"\n",
    "            network.save(path)\n",
    "            print(f\"üíæ Modelo Keras guardado en {path}\")\n",
    "            return results\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Error en bloque Keras:\", e)\n",
    "\n",
    "    # ================ PYTORCH ================\n",
    "    try:\n",
    "        if isinstance(network, nn.Module):\n",
    "            print(\"‚úÖ Red PyTorch detectada. Iniciando entrenamiento‚Ä¶\")\n",
    "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            network.to(device).train()\n",
    "\n",
    "            X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "            y_tensor = torch.tensor(y, dtype=torch.long).to(device)\n",
    "            opt      = optim.Adam(network.parameters(), lr=learning_rate) if optimizer == \"adam\" else optim.SGD(network.parameters(), lr=learning_rate)\n",
    "            loss_fn  = nn.CrossEntropyLoss()\n",
    "\n",
    "            num_samples = X.shape[0]\n",
    "            while True:\n",
    "                if time.time() - start_time >= timeout - 0.1:\n",
    "                    break\n",
    "                idx = np.random.choice(num_samples, batch_size, replace=False)\n",
    "                opt.zero_grad()\n",
    "                loss = loss_fn(network(X_tensor[idx]), y_tensor[idx])\n",
    "                loss.backward(); opt.step()\n",
    "                elapsed = round(time.time() - start_time, 4)\n",
    "                results.append((elapsed, float(loss.item())))\n",
    "\n",
    "            # ‚îÄ‚îÄ‚îÄ Guardar modelo ‚îÄ‚îÄ‚îÄ\n",
    "            path = f\"models/torch_{tag}.pt\"\n",
    "            torch.save(network.state_dict(), path)\n",
    "            print(f\"üíæ Modelo PyTorch guardado en {path}\")\n",
    "            return results\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Error en bloque PyTorch:\", e)\n",
    "\n",
    "    # ================ SKLEARN ================\n",
    "    try:\n",
    "        if isinstance(network, MLPClassifier):\n",
    "            print(\"‚úÖ Red sklearn detectada. Iniciando entrenamiento‚Ä¶\")\n",
    "            num_samples = X.shape[0]\n",
    "            classes     = np.unique(y)\n",
    "            while True:\n",
    "                if time.time() - start_time >= timeout - 0.1:\n",
    "                    break\n",
    "                idx = np.random.choice(num_samples, batch_size, replace=False)\n",
    "                network.partial_fit(X[idx], y[idx], classes=classes)\n",
    "\n",
    "                # estimar p√©rdida\n",
    "                probs = network.predict_proba(X[idx])\n",
    "                loss  = -np.mean(np.log(probs + 1e-9)[np.arange(len(idx)), y[idx]])\n",
    "                elapsed = round(time.time() - start_time, 4)\n",
    "                results.append((elapsed, float(loss)))\n",
    "\n",
    "            # ‚îÄ‚îÄ‚îÄ Guardar modelo ‚îÄ‚îÄ‚îÄ\n",
    "            path = f\"models/sklearn_{tag}.pkl\"\n",
    "            joblib.dump(network, path)\n",
    "            print(f\"üíæ Modelo sklearn guardado en {path}\")\n",
    "            return results\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Error en bloque sklearn:\", e)\n",
    "\n",
    "    print(\"‚ö†Ô∏è Ning√∫n framework compatible fue detectado.\")\n",
    "    raise ValueError(f\"Tipo de red no reconocido: {type(network)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c4d2323a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñ∂Ô∏è  Ejecutando keras_bs256_adam_lr0.001\n",
      "üîç Detectando tipo de red: <class 'keras.src.models.sequential.Sequential'>\n",
      "‚úÖ Red Keras detectada. Iniciando entrenamiento‚Ä¶\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pipe/anaconda3/envs/deeplearning/lib/python3.10/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Modelo Keras guardado en models/keras_adam_bs256_lr0.001.keras\n",
      "‚ñ∂Ô∏è  Ejecutando torch_bs256_adam_lr0.001\n",
      "üîç Detectando tipo de red: <class 'torch.nn.modules.container.Sequential'>\n",
      "‚úÖ Red PyTorch detectada. Iniciando entrenamiento‚Ä¶\n",
      "üíæ Modelo PyTorch guardado en models/torch_adam_bs256_lr0.001.pt\n",
      "‚ñ∂Ô∏è  Ejecutando sklearn_bs256_adam_lr0.001\n",
      "üîç Detectando tipo de red: <class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "‚úÖ Red sklearn detectada. Iniciando entrenamiento‚Ä¶\n",
      "üíæ Modelo sklearn guardado en models/sklearn_adam_bs256_lr0.001.pkl\n"
     ]
    }
   ],
   "source": [
    "# --- carga CIFAR-10 y aplana ---\n",
    "(X_tr, y_tr), _ = cifar10.load_data()\n",
    "X_tr = X_tr.reshape((X_tr.shape[0], -1)).astype(\"float32\") / 255.0\n",
    "y_tr = y_tr.flatten()\n",
    "\n",
    "\n",
    "# frameworks  = [\"keras\", \"torch\", \"sklearn\"]\n",
    "# batch_sizes = [16, 64, 256, 2048]\n",
    "# optimizers  = [\"sgd\", \"adam\"]\n",
    "# lrs         = [0.001, 0.01]\n",
    "\n",
    "\n",
    "frameworks  = [\"keras\", \"torch\", \"sklearn\"]\n",
    "batch_sizes = [256]\n",
    "optimizers  = [\"adam\"]\n",
    "lrs         = [0.001]\n",
    "\n",
    "out_dir = \"csv_logs\";  os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "for fw, bs, opt, lr in itertools.product(frameworks, batch_sizes, optimizers, lrs):\n",
    "    tag = f\"{fw}_bs{bs}_{opt}_lr{lr}\"\n",
    "    print(\"‚ñ∂Ô∏è  Ejecutando\", tag, flush=True)\n",
    "\n",
    "    model = make_model(fw, seed=7)\n",
    "    results = train_network(model, X_tr, y_tr,\n",
    "                            optimizer=opt,\n",
    "                            learning_rate=lr,\n",
    "                            batch_size=bs,\n",
    "                            timeout=10)       # 10 min\n",
    "\n",
    "    with open(os.path.join(out_dir, tag + \".csv\"), \"w\", newline=\"\") as f:\n",
    "        wr = csv.writer(f)\n",
    "        wr.writerow([\"time_s\", \"loss\"])\n",
    "        wr.writerows(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2cb842ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(y, k=30):\n",
    "    return pd.Series(y).rolling(window=k, min_periods=1).mean().values\n",
    "\n",
    "def gif_config_progress(config_tag, n_frames=200, fps=12, y_max=5):\n",
    "    \"\"\"\n",
    "    Genera un GIF que compara Keras, PyTorch y sklearn para una misma configuraci√≥n.\n",
    "    `config_tag` es la parte com√∫n del nombre, ej.: 'bs16_sgd_lr0.001'\n",
    "    \"\"\"\n",
    "    FRAMEWORKS = [\"keras\", \"torch\", \"sklearn\"]\n",
    "    curves, max_time = [], 0\n",
    "    for fw in FRAMEWORKS:\n",
    "        path = f\"csv_logs/{fw}_{config_tag}.csv\"\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"‚ö†Ô∏è  Falta {path} (se omitir√°)\")\n",
    "            continue\n",
    "        df = pd.read_csv(path)\n",
    "        t, l = df[\"time_s\"].values, df[\"loss\"].values\n",
    "        curves.append((fw.capitalize(), t, l))\n",
    "        max_time = max(max_time, t[-1])\n",
    "\n",
    "    if len(curves) < 2:\n",
    "        print(\"‚ùå Se necesitan al menos 2 frameworks para comparar.\")\n",
    "        return\n",
    "\n",
    "    frame_times = np.linspace(0, max_time, n_frames)\n",
    "    frames = []\n",
    "    print(f\"üéûÔ∏è  Generando {n_frames} frames para {config_tag}‚Ä¶\")\n",
    "    for t_cut in tqdm(frame_times):\n",
    "        fig, ax = plt.subplots(figsize=(8,5))\n",
    "        for label, t, l in curves:\n",
    "            idx = np.searchsorted(t, t_cut, side=\"right\")\n",
    "            if idx > 1:\n",
    "                # suavizamos solo lo que vamos a dibujar\n",
    "                l_smooth = smooth(l[:idx])\n",
    "                t_smooth = t[:len(l_smooth)]\n",
    "                ax.plot(t_smooth, l_smooth, label=label, linewidth=2)\n",
    "\n",
    "        ax.set(xlim=(0, math.ceil(max_time)),\n",
    "               ylim=(0, y_max),\n",
    "               xlabel=\"Tiempo [s]\",\n",
    "               ylabel=\"P√©rdida\",\n",
    "               title=f\"Comparaci√≥n de frameworks ‚Äì {config_tag} ‚Äì t={t_cut:0.1f}s\")\n",
    "        ax.grid(alpha=0.3)\n",
    "        ax.legend(fontsize=10)\n",
    "        fig.tight_layout()\n",
    "\n",
    "        buf = io.BytesIO()\n",
    "        fig.savefig(buf, format=\"png\")\n",
    "        plt.close(fig)\n",
    "        buf.seek(0)\n",
    "        frames.append(imageio.v2.imread(buf))\n",
    "\n",
    "    gif_name = f\"compare_{config_tag}.gif\"\n",
    "    imageio.mimsave(gif_name, frames, fps=fps)\n",
    "    print(\"‚úÖ GIF guardado en\", gif_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "432269d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéûÔ∏è  Generando 200 frames para bs256_adam_lr0.001‚Ä¶\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1164/2073557707.py:44: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  ax.legend(fontsize=10)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:23<00:00,  8.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ GIF guardado en compare_bs256_adam_lr0.001.gif\n"
     ]
    }
   ],
   "source": [
    "gif_config_progress(\"bs256_adam_lr0.001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "89173d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def gif_framework_progress(framework, n_frames=200, fps=12):\n",
    "#     csv_files = sorted(glob.glob(f\"csv_logs/{framework}_*.csv\"))\n",
    "#     if not csv_files:\n",
    "#         print(\"‚ùå No se encontraron CSV para\", framework)\n",
    "#         return\n",
    "    \n",
    "#     # Cargar todas las curvas\n",
    "#     curves, max_time = [], 0\n",
    "#     for path in csv_files:\n",
    "#         df = pd.read_csv(path)\n",
    "#         t, l = df[\"time_s\"].values, df[\"loss\"].values\n",
    "#         curves.append((os.path.basename(path).replace(\".csv\", \"\"), t, l))\n",
    "#         max_time = max(max_time, t[-1])\n",
    "    \n",
    "#     frame_times = np.linspace(0, max_time, n_frames)\n",
    "#     frames = []\n",
    "#     print(f\"üéûÔ∏è  Generando {n_frames} frames para {framework}‚Ä¶\")\n",
    "#     for t_cut in tqdm(frame_times):\n",
    "#         fig, ax = plt.subplots(figsize=(12,8))\n",
    "#         for label, t, l in curves:\n",
    "#             idx = np.searchsorted(t, t_cut, side=\"right\")\n",
    "#             if idx > 1:\n",
    "#                 ax.plot(t[:idx], l[:idx], label=label, linewidth=1)\n",
    "#         ax.set(xlim=(0, math.ceil(max_time)), ylim=(0,10),\n",
    "#                xlabel=\"Tiempo [s]\", ylabel=\"P√©rdida\",\n",
    "#                title=f\"{framework.upper()} ‚Äì hasta {t_cut:0.1f}s\")\n",
    "#         ax.grid(alpha=0.3)\n",
    "#         ax.legend(fontsize=6, ncol=2, loc=\"upper right\", frameon=False)\n",
    "#         fig.tight_layout()\n",
    "        \n",
    "#         # ‚îÄ‚îÄ‚îÄ convertir figura a array ‚îÄ‚îÄ‚îÄ\n",
    "#         buf = io.BytesIO()\n",
    "#         fig.savefig(buf, format=\"png\")       # guarda figura en memoria\n",
    "#         plt.close(fig)\n",
    "#         buf.seek(0)\n",
    "#         frames.append(imageio.v2.imread(buf))  # lee PNG desde el buffer\n",
    "\n",
    "#     gif_name = f\"{framework}_all_configs.gif\"\n",
    "#     imageio.mimsave(gif_name, frames, fps=fps)\n",
    "#     print(\"‚úÖ GIF guardado en\", gif_name)\n",
    "\n",
    "# # Ejemplo de uso\n",
    "# gif_framework_progress(\"keras\")   # o \"torch\", \"sklearn\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c35ee238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÜ  TOP 10 configuraciones (promedio de las √∫ltimas 10 p√©rdidas):\n",
      " 1. keras_bs256_sgd_lr0.01                    avg_loss = 0.4088\n",
      " 2. keras_bs64_sgd_lr0.01                     avg_loss = 0.5339\n",
      " 3. keras_bs64_adam_lr0.001                   avg_loss = 0.6213\n",
      " 4. keras_bs2048_adam_lr0.001                 avg_loss = 0.6849\n",
      " 5. sklearn_bs2048_adam_lr0.001               avg_loss = 0.7162\n",
      " 6. sklearn_bs2048_sgd_lr0.01                 avg_loss = 0.7169\n",
      " 7. sklearn_bs2048_sgd_lr0.001                avg_loss = 0.7178\n",
      " 8. sklearn_bs2048_adam_lr0.01                avg_loss = 0.7359\n",
      " 9. keras_bs16_sgd_lr0.01                     avg_loss = 0.9728\n",
      "10. sklearn_bs256_sgd_lr0.01                  avg_loss = 1.0331\n"
     ]
    }
   ],
   "source": [
    "import glob, os, pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "CSV_DIR = \"csv_logs\"   # carpeta donde guardas los *.csv\n",
    "K_LAST  = 10           # cu√°ntos pasos finales promediar\n",
    "\n",
    "def avg_last_losses(path, k=K_LAST):\n",
    "    \"\"\"Promedio de las k √∫ltimas p√©rdidas del CSV (o menos si hay pocos datos).\"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    return float(df[\"loss\"].tail(k).mean()) if not df.empty else np.inf\n",
    "\n",
    "def top_configs(csv_dir=CSV_DIR, k_last=K_LAST, top_n=10):\n",
    "    entries = []\n",
    "    for csv_path in glob.glob(os.path.join(csv_dir, \"*.csv\")):\n",
    "        tag  = os.path.basename(csv_path).replace(\".csv\", \"\")  # nombre sin extensi√≥n\n",
    "        loss = avg_last_losses(csv_path, k=k_last)\n",
    "        if np.isfinite(loss):\n",
    "            entries.append((loss, tag))        # (valor, configuraci√≥n)\n",
    "\n",
    "    # Ordena por menor p√©rdida y toma los top_n\n",
    "    return sorted(entries, key=lambda x: x[0])[:top_n]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    top10 = top_configs(top_n=10)\n",
    "    if top10:\n",
    "        print(f\"\\nüèÜ  TOP 10 configuraciones (promedio de las √∫ltimas {K_LAST} p√©rdidas):\")\n",
    "        for rank, (loss, tag) in enumerate(top10, start=1):\n",
    "            print(f\"{rank:2d}. {tag:<40}  avg_loss = {loss:.4f}\")\n",
    "    else:\n",
    "        print(\"No se encontraron archivos CSV en\", CSV_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
